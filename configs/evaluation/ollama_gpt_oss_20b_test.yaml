experiment_name: ollama_gpt_oss_20b_test
description: Ollama test with gpt-oss:20b model (13GB) for performance evaluation
mode: accuracy

# Input configuration - using existing benchmark
benchmark_paths:
  - data/benchmarks/collected/01_logic_reasoning/easy/collected_samples.json

output_dir: data/reports/ollama_gpt_oss_20b_test

# Model configuration using gpt-oss:20b
models:
  - name: "gpt-oss:20b"
    provider: ollama
    temperature: 0.7
    max_tokens: 200
    timeout: 90

# Simple transformations to test the pipeline
transformations:
  enabled_types:
    - language_translation
  
  # Simple language settings for quick test
  languages:
    - constructed_agglutinative_1
  language_complexity: 1
  
  # General settings
  seed: 1
  batch_size: 2

# Evaluation settings (reasonable for 20b model testing)
max_samples: 10                   # Conservative sample size for large 20b model
sample_seed: 1
max_concurrent_requests: 1        # Sequential processing for local models
save_interval: 4

# Analysis settings (skip for quick testing)
generate_plots: false
calculate_significance: false